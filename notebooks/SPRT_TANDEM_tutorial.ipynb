{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MIT License\n",
    "\n",
    "Copyright (c) 2021 Taiki Miyagawa and Akinori F. Ebihara\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPRT-TANDEM tutorial\n",
    "- This notebook is supposed to be opened on Google Colab. For details, see the README of this repo.\n",
    "- GPU accelerator is required. From the \"Runtime\" tab on top of the notebook, choose \"Change runtime type\" to select a GPU.\n",
    "- First, let's upload the repo onto Colab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3\n",
    "from itertools import zip_longest\n",
    "\n",
    "!git clone https://github.com/Akinori-F-Ebihara/SPRT-TANDEM-tutorial\n",
    "os.chdir('./SPRT-TANDEM-tutorial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the Nosaic-MNIST database\n",
    "- The script ``make_nmnist.py`` will generate train and test Nosaic-MNIST databases.\n",
    "- Two files, ``./data-directory/nosaic_mnist_train.tfrecords`` and ``./data-directory/nosaic_mnist_test.tfrecords`` will be generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python make_nmnist_testonly.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize example sequential data\n",
    "- Choose one random test data to visualize\n",
    "- The shape of one data is _(duration, width, height, channel) = (20, 28, 28, 1)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration=20 # the length of sequential data\n",
    "\n",
    "import tensorflow as tf\n",
    "from datasets.data_processing import read_tfrecords_nosaic_mnist,\\\n",
    "    decode_nosaic_mnist, binarize_labels_nosaic_mnist,\\\n",
    "    normalize_images_nosaic_mnist, reshape_for_featext\n",
    "\n",
    "# Reed the test tfr\n",
    "def _parse_image_function(example_proto):\n",
    "        return tf.io.parse_single_example(example_proto, {\n",
    "                    'video': tf.io.FixedLenFeature([], tf.string),\n",
    "                    'label': tf.io.FixedLenFeature([],tf.int64)\n",
    "                    })\n",
    "\n",
    "record_file_test='./data-directory/nosaic_mnist_test.tfrecords'\n",
    "batch_size = 1\n",
    "\n",
    "raw_image_dataset_test = tf.data.TFRecordDataset(record_file_test)\n",
    "parsed_image_dataset_test = raw_image_dataset_test.map(_parse_image_function)\n",
    "parsed_image_dataset_test = parsed_image_dataset_test.batch(\n",
    "    batch_size, drop_remainder=True) ###\n",
    "    \n",
    "for iter_b, feats in enumerate(parsed_image_dataset_test):\n",
    "    x_batch, y_batch = decode_nosaic_mnist(feats, duration=duration)\n",
    "    if np.random.rand() > 0.5: break\n",
    "\n",
    "print('Shape of a data in NMNIST:', x_batch[0].shape)\n",
    "print('Digit label: ', y_batch.numpy())\n",
    "\n",
    "plt.figure(figsize = (16,8))\n",
    "for i in range(duration):\n",
    "  plt.subplot(4, 5, i+1)\n",
    "  plt.imshow(np.squeeze(x_batch[0, i]), cmap='gray')\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.title(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the pretrained model\n",
    "### Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.backbones_fe import ResNetModel, get_ressize_dependent_params, checkpoint_logger_tmp\n",
    "from models.backbones_ti import LSTMModelLite\n",
    "from models.losses import get_loss_fe, get_gradient_lstm_ver2\n",
    "\n",
    "root_ckptlogs = \"./data-directory\"\n",
    "path_resume_FE =  \"./data-directory/trained_models/FE_NMNIST/\"\n",
    "resnet_size = 44\n",
    "nb_cls = 2\n",
    "final_size = 32\n",
    "resnet_version = 1\n",
    "\n",
    "# retrieve ResNet related parameters    \n",
    "dict_resparams = get_ressize_dependent_params(resnet_version, resnet_size)\n",
    "\n",
    "# feature extractor\n",
    "model_FE = ResNetModel(\n",
    "    resnet_size=resnet_size,\n",
    "    bottleneck=dict_resparams[\"bottleneck\"],\n",
    "    num_classes=nb_cls,\n",
    "    kernel_size=dict_resparams[\"kernel_size\"],\n",
    "    conv_stride=dict_resparams[\"conv_stride\"],\n",
    "    first_pool_size=dict_resparams[\"first_pool_size\"],\n",
    "    first_pool_stride=dict_resparams[\"first_pool_stride\"],\n",
    "    block_sizes=dict_resparams[\"block_sizes\"],\n",
    "    block_strides=dict_resparams[\"block_strides\"],\n",
    "    final_size=final_size,\n",
    "    resnet_version=resnet_version,\n",
    "    data_format='channels_last',\n",
    "    dtype=tf.float32\n",
    ")\n",
    "\n",
    "# Checkpoint\n",
    "now = \"0\"\n",
    "_, ckpt_manager = checkpoint_logger_tmp(\n",
    "    model_FE, \n",
    "    True, \n",
    "    root_ckptlogs, \n",
    "    subproject_name=\"_\", \n",
    "    exp_phase=\"_\",\n",
    "    comment=\"_\", \n",
    "    time_stamp=now, \n",
    "    path_resume=path_resume_FE)\n",
    "\n",
    "if nb_cls == 2:\n",
    "    y_batch = binarize_labels_nosaic_mnist(y_batch)\n",
    "\n",
    "x_batch, y_batch = reshape_for_featext(x_batch, y_batch, (28, 28, 1)) \n",
    "    # (bs*duration, 28,28,1), (bs*duration,)\n",
    "x_batch = normalize_images_nosaic_mnist(x_batch)\n",
    "            \n",
    "# 2. Extract features\n",
    "_, losses, _, feats_batch = get_loss_fe(\n",
    "model_FE, \n",
    "x_batch, \n",
    "y_batch, \n",
    "training=False, \n",
    "param_wd=None, \n",
    "flag_wd=False,\n",
    "calc_grad=False\n",
    ")\n",
    "\n",
    "plt.imshow(np.transpose(feats_batch), aspect='auto')\n",
    "# Reshape (batch, duration, final size)\n",
    "feats_batch = tf.reshape(feats_batch, (batch_size, duration, final_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal integrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_sprt = 1\n",
    "duration = 20\n",
    "width_lstm = 64\n",
    "\n",
    "model_TI = LSTMModelLite(\n",
    "    nb_cls, \n",
    "    width_lstm, \n",
    "    dropout=0.0, \n",
    "    activation='tanh')\n",
    "\n",
    "# Calc loss and grad, and backpropagation\n",
    "_, losses, logits_concat, LLRs = \\\n",
    "                get_gradient_lstm_ver2(\n",
    "    model_TI, \n",
    "    feats_batch, \n",
    "    y_batch, \n",
    "    training=True, \n",
    "    order_sprt=order_sprt,\n",
    "    duration=duration,\n",
    "    oblivious=False,\n",
    "    version='E',\n",
    "    param_multiplet_loss=1.0, \n",
    "    param_llr_loss=1.0, \n",
    "    param_wd=0.00001, \n",
    "    flag_wd=False,\n",
    "    flag_mgn=False,\n",
    "    calc_grad=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate log-likelihood ratio (LLR) and plot the LLR trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the speed-accuracy tradeoff (SAT) curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
